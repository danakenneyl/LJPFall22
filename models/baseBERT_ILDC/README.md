---
license: apache-2.0
tags:
- generated_from_trainer
metrics:
- accuracy
model-index:
- name: baseBERT
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# baseBERT

This model is a fine-tuned version of [bert-base-uncased](https://huggingface.co/bert-base-uncased) on an unknown dataset.
It achieves the following results on the evaluation set:
- Loss: 0.6857
- Accuracy: 0.5925

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 4e-06
- train_batch_size: 8
- eval_batch_size: 8
- seed: 42
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- num_epochs: 3.0

### Training results

| Training Loss | Epoch | Step  | Validation Loss | Accuracy |
|:-------------:|:-----:|:-----:|:---------------:|:--------:|
| No log        | 0.03  | 100   | 0.6850          | 0.5692   |
| No log        | 0.06  | 200   | 0.6837          | 0.5692   |
| No log        | 0.09  | 300   | 0.6818          | 0.5692   |
| No log        | 0.11  | 400   | 0.6829          | 0.5692   |
| 0.6869        | 0.14  | 500   | 0.6820          | 0.5692   |
| 0.6869        | 0.17  | 600   | 0.6851          | 0.5692   |
| 0.6869        | 0.2   | 700   | 0.6800          | 0.5692   |
| 0.6869        | 0.23  | 800   | 0.6773          | 0.5692   |
| 0.6869        | 0.26  | 900   | 0.6760          | 0.5692   |
| 0.6799        | 0.29  | 1000  | 0.6728          | 0.5729   |
| 0.6799        | 0.32  | 1100  | 0.6714          | 0.5724   |
| 0.6799        | 0.34  | 1200  | 0.6771          | 0.5758   |
| 0.6799        | 0.37  | 1300  | 0.6715          | 0.5862   |
| 0.6799        | 0.4   | 1400  | 0.6748          | 0.5801   |
| 0.6728        | 0.43  | 1500  | 0.6668          | 0.5893   |
| 0.6728        | 0.46  | 1600  | 0.6662          | 0.5953   |
| 0.6728        | 0.49  | 1700  | 0.6665          | 0.5882   |
| 0.6728        | 0.52  | 1800  | 0.6947          | 0.5873   |
| 0.6728        | 0.55  | 1900  | 0.6821          | 0.5887   |
| 0.6639        | 0.57  | 2000  | 0.6684          | 0.5922   |
| 0.6639        | 0.6   | 2100  | 0.6723          | 0.5681   |
| 0.6639        | 0.63  | 2200  | 0.6646          | 0.5896   |
| 0.6639        | 0.66  | 2300  | 0.6660          | 0.5939   |
| 0.6639        | 0.69  | 2400  | 0.6666          | 0.5867   |
| 0.6705        | 0.72  | 2500  | 0.6655          | 0.5925   |
| 0.6705        | 0.75  | 2600  | 0.6737          | 0.5859   |
| 0.6705        | 0.78  | 2700  | 0.6675          | 0.5882   |
| 0.6705        | 0.8   | 2800  | 0.6776          | 0.5841   |
| 0.6705        | 0.83  | 2900  | 0.6661          | 0.5867   |
| 0.669         | 0.86  | 3000  | 0.6658          | 0.5896   |
| 0.669         | 0.89  | 3100  | 0.6677          | 0.5902   |
| 0.669         | 0.92  | 3200  | 0.6652          | 0.5833   |
| 0.669         | 0.95  | 3300  | 0.6819          | 0.5827   |
| 0.669         | 0.98  | 3400  | 0.6694          | 0.5930   |
| 0.6579        | 1.01  | 3500  | 0.6687          | 0.5882   |
| 0.6579        | 1.03  | 3600  | 0.6710          | 0.5856   |
| 0.6579        | 1.06  | 3700  | 0.6825          | 0.5925   |
| 0.6579        | 1.09  | 3800  | 0.6813          | 0.5899   |
| 0.6579        | 1.12  | 3900  | 0.6731          | 0.5925   |
| 0.6601        | 1.15  | 4000  | 0.6648          | 0.5951   |
| 0.6601        | 1.18  | 4100  | 0.6653          | 0.5962   |
| 0.6601        | 1.21  | 4200  | 0.6770          | 0.5951   |
| 0.6601        | 1.23  | 4300  | 0.6695          | 0.5951   |
| 0.6601        | 1.26  | 4400  | 0.6680          | 0.5876   |
| 0.6588        | 1.29  | 4500  | 0.6687          | 0.5893   |
| 0.6588        | 1.32  | 4600  | 0.6706          | 0.5945   |
| 0.6588        | 1.35  | 4700  | 0.6679          | 0.5930   |
| 0.6588        | 1.38  | 4800  | 0.6683          | 0.5882   |
| 0.6588        | 1.41  | 4900  | 0.6725          | 0.5922   |
| 0.6515        | 1.44  | 5000  | 0.6724          | 0.5974   |
| 0.6515        | 1.46  | 5100  | 0.6727          | 0.5905   |
| 0.6515        | 1.49  | 5200  | 0.6701          | 0.5879   |
| 0.6515        | 1.52  | 5300  | 0.6880          | 0.5942   |
| 0.6515        | 1.55  | 5400  | 0.6720          | 0.5910   |
| 0.6452        | 1.58  | 5500  | 0.6727          | 0.5876   |
| 0.6452        | 1.61  | 5600  | 0.6785          | 0.5887   |
| 0.6452        | 1.64  | 5700  | 0.6755          | 0.5847   |
| 0.6452        | 1.67  | 5800  | 0.6699          | 0.5870   |
| 0.6452        | 1.69  | 5900  | 0.6854          | 0.5902   |
| 0.6466        | 1.72  | 6000  | 0.6887          | 0.5925   |
| 0.6466        | 1.75  | 6100  | 0.6749          | 0.5833   |
| 0.6466        | 1.78  | 6200  | 0.6699          | 0.5922   |
| 0.6466        | 1.81  | 6300  | 0.6857          | 0.5925   |
| 0.6466        | 1.84  | 6400  | 0.6780          | 0.5956   |
| 0.6557        | 1.87  | 6500  | 0.6707          | 0.5908   |
| 0.6557        | 1.9   | 6600  | 0.6665          | 0.5890   |
| 0.6557        | 1.92  | 6700  | 0.6699          | 0.5890   |
| 0.6557        | 1.95  | 6800  | 0.6860          | 0.5939   |
| 0.6557        | 1.98  | 6900  | 0.6746          | 0.5913   |
| 0.6514        | 2.01  | 7000  | 0.6745          | 0.5919   |
| 0.6514        | 2.04  | 7100  | 0.6699          | 0.5905   |
| 0.6514        | 2.07  | 7200  | 0.6759          | 0.5922   |
| 0.6514        | 2.1   | 7300  | 0.6701          | 0.5859   |
| 0.6514        | 2.13  | 7400  | 0.6822          | 0.5951   |
| 0.6482        | 2.15  | 7500  | 0.6718          | 0.5867   |
| 0.6482        | 2.18  | 7600  | 0.6776          | 0.5870   |
| 0.6482        | 2.21  | 7700  | 0.6809          | 0.5887   |
| 0.6482        | 2.24  | 7800  | 0.6850          | 0.5930   |
| 0.6482        | 2.27  | 7900  | 0.6794          | 0.5867   |
| 0.6352        | 2.3   | 8000  | 0.6784          | 0.5902   |
| 0.6352        | 2.33  | 8100  | 0.6814          | 0.5908   |
| 0.6352        | 2.35  | 8200  | 0.6832          | 0.5870   |
| 0.6352        | 2.38  | 8300  | 0.6858          | 0.5908   |
| 0.6352        | 2.41  | 8400  | 0.6840          | 0.5899   |
| 0.6308        | 2.44  | 8500  | 0.6841          | 0.5913   |
| 0.6308        | 2.47  | 8600  | 0.6955          | 0.5905   |
| 0.6308        | 2.5   | 8700  | 0.6818          | 0.5867   |
| 0.6308        | 2.53  | 8800  | 0.6863          | 0.5945   |
| 0.6308        | 2.56  | 8900  | 0.6862          | 0.5933   |
| 0.6353        | 2.58  | 9000  | 0.6821          | 0.5928   |
| 0.6353        | 2.61  | 9100  | 0.6865          | 0.5933   |
| 0.6353        | 2.64  | 9200  | 0.6813          | 0.5885   |
| 0.6353        | 2.67  | 9300  | 0.6842          | 0.5928   |
| 0.6353        | 2.7   | 9400  | 0.6865          | 0.5933   |
| 0.6294        | 2.73  | 9500  | 0.6884          | 0.5942   |
| 0.6294        | 2.76  | 9600  | 0.6862          | 0.5919   |
| 0.6294        | 2.79  | 9700  | 0.6866          | 0.5908   |
| 0.6294        | 2.81  | 9800  | 0.6890          | 0.5916   |
| 0.6294        | 2.84  | 9900  | 0.6885          | 0.5930   |
| 0.632         | 2.87  | 10000 | 0.6903          | 0.5916   |
| 0.632         | 2.9   | 10100 | 0.6864          | 0.5925   |
| 0.632         | 2.93  | 10200 | 0.6855          | 0.5916   |
| 0.632         | 2.96  | 10300 | 0.6862          | 0.5925   |
| 0.632         | 2.99  | 10400 | 0.6858          | 0.5930   |


### Framework versions

- Transformers 4.24.0
- Pytorch 1.10.0a0+0aef44c
- Datasets 2.7.0
- Tokenizers 0.13.2
